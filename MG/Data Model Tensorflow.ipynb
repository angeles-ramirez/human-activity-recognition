{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>ts</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Profile_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.190048</td>\n",
       "      <td>-0.078262</td>\n",
       "      <td>-0.986176</td>\n",
       "      <td>1578568648</td>\n",
       "      <td>stand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140366</td>\n",
       "      <td>-0.068359</td>\n",
       "      <td>-0.998215</td>\n",
       "      <td>1578568648</td>\n",
       "      <td>stand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003952</td>\n",
       "      <td>-0.032806</td>\n",
       "      <td>-0.969467</td>\n",
       "      <td>1578568648</td>\n",
       "      <td>stand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010345</td>\n",
       "      <td>0.084564</td>\n",
       "      <td>-0.947189</td>\n",
       "      <td>1578568648</td>\n",
       "      <td>stand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116348</td>\n",
       "      <td>-0.303986</td>\n",
       "      <td>-1.067520</td>\n",
       "      <td>1578568648</td>\n",
       "      <td>stand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z          ts Activity  Profile_code\n",
       "0  0.190048 -0.078262 -0.986176  1578568648    stand             3\n",
       "1  0.140366 -0.068359 -0.998215  1578568648    stand             3\n",
       "2  0.003952 -0.032806 -0.969467  1578568648    stand             3\n",
       "3 -0.010345  0.084564 -0.947189  1578568648    stand             3\n",
       "4  0.116348 -0.303986 -1.067520  1578568648    stand             3"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_data = pd.read_csv(\"Outputs/output_file_acc.csv\")\n",
    "activity_data.head()\n",
    "activity_data.Profile = pd.Categorical(activity_data.Profile)\n",
    "activity_data['Profile_code'] = activity_data.Profile.cat.codes\n",
    "\n",
    "clean_data = activity_data.drop(\"Profile\", axis=1)\n",
    "clean_data = clean_data.drop(\"Date_time\", axis=1)\n",
    "\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how many training examples exist for each of the six activities\n",
    "clean_data['Activity'].value_counts().plot(kind='bar',\n",
    "                                   title='Training Examples by Activity Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Better understand how the recordings are spread across the different\n",
    "# users who participated in the study\n",
    "clean_data['Profile_code'].value_counts().plot(kind='bar',\n",
    "                                  title='Training Examples by User')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>Activity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56800</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56801</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56802</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56803</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56804</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56805</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56806</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56807</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56808</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56811</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56812</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56813</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56814</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56815</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56816</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56817</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56818</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56819</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56820</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56821</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56822</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56823</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56824</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56825</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56826</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56827</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56828</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56829</th>\n",
       "      <td>stairsu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28065 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Activity  Activity_code\n",
       "5709   stairsu              3\n",
       "5710   stairsu              3\n",
       "5711   stairsu              3\n",
       "5712   stairsu              3\n",
       "5713   stairsu              3\n",
       "5714   stairsu              3\n",
       "5715   stairsu              3\n",
       "5716   stairsu              3\n",
       "5717   stairsu              3\n",
       "5718   stairsu              3\n",
       "5719   stairsu              3\n",
       "5720   stairsu              3\n",
       "5721   stairsu              3\n",
       "5722   stairsu              3\n",
       "5723   stairsu              3\n",
       "5724   stairsu              3\n",
       "5725   stairsu              3\n",
       "5726   stairsu              3\n",
       "5727   stairsu              3\n",
       "5728   stairsu              3\n",
       "5729   stairsu              3\n",
       "5730   stairsu              3\n",
       "5731   stairsu              3\n",
       "5732   stairsu              3\n",
       "5733   stairsu              3\n",
       "5734   stairsu              3\n",
       "5735   stairsu              3\n",
       "5736   stairsu              3\n",
       "5737   stairsu              3\n",
       "5738   stairsu              3\n",
       "...        ...            ...\n",
       "56800  stairsu              3\n",
       "56801  stairsu              3\n",
       "56802  stairsu              3\n",
       "56803  stairsu              3\n",
       "56804  stairsu              3\n",
       "56805  stairsu              3\n",
       "56806  stairsu              3\n",
       "56807  stairsu              3\n",
       "56808  stairsu              3\n",
       "56809  stairsu              3\n",
       "56810  stairsu              3\n",
       "56811  stairsu              3\n",
       "56812  stairsu              3\n",
       "56813  stairsu              3\n",
       "56814  stairsu              3\n",
       "56815  stairsu              3\n",
       "56816  stairsu              3\n",
       "56817  stairsu              3\n",
       "56818  stairsu              3\n",
       "56819  stairsu              3\n",
       "56820  stairsu              3\n",
       "56821  stairsu              3\n",
       "56822  stairsu              3\n",
       "56823  stairsu              3\n",
       "56824  stairsu              3\n",
       "56825  stairsu              3\n",
       "56826  stairsu              3\n",
       "56827  stairsu              3\n",
       "56828  stairsu              3\n",
       "56829  stairsu              3\n",
       "\n",
       "[28065 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define column name of the label vector\n",
    "#stand =4\n",
    "#stairsd =2\n",
    "#stairsu = 3\n",
    "#laying = 0\n",
    "#sit = 1\n",
    "#walk = 5\n",
    "clean_data.Activity = pd.Categorical(clean_data.Activity)\n",
    "clean_data['Activity_code'] = clean_data.Activity.cat.codes\n",
    "df = clean_data[['Activity','Activity_code']]\n",
    "df.loc[df['Activity_code'] ==5]\n",
    "clean_data1 = clean_data.drop(\"Activity\", axis=1) \n",
    "clean_data1\n",
    "df.loc[df['Activity_code'] ==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = clean_data[clean_data['Profile_code'] > 3]\n",
    "df_train = clean_data[clean_data['Profile_code'] <= 3]\n",
    "#df_train = clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.90048000e-01, -7.82620000e-02, -9.86176000e-01,\n",
       "         1.57856865e+09,  3.00000000e+00],\n",
       "       [ 1.40366000e-01, -6.83590000e-02, -9.98215000e-01,\n",
       "         1.57856865e+09,  3.00000000e+00],\n",
       "       [ 3.95200000e-03, -3.28060000e-02, -9.69467000e-01,\n",
       "         1.57856865e+09,  3.00000000e+00],\n",
       "       ...,\n",
       "       [-1.78360000e-01,  1.25443000e-01, -9.65302000e-01,\n",
       "         1.57857603e+09,  2.00000000e+00],\n",
       "       [-2.56714000e-01,  1.32019000e-01, -9.20105000e-01,\n",
       "         1.57857603e+09,  2.00000000e+00],\n",
       "       [-3.57101000e-01,  1.49612000e-01, -9.38354000e-01,\n",
       "         1.57857603e+09,  2.00000000e+00]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df = df_train[[\"X\",\"Y\",\"Z\",\"ts\",\"Profile_code\"]]\n",
    "x_train_df \n",
    "X_train = x_train_df.values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df = df_train[\"Activity_code\"]\n",
    "y_train_df\n",
    "y_train = to_categorical(y_train_df)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5044, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Read the testing data\n",
    "X_test_df = df_test[[\"X\",\"Y\",\"Z\",\"ts\",\"Profile_code\"]]\n",
    "X_test = X_test_df.values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5044, 6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the testing labels\n",
    "y_test_df = df_test[\"Activity_code\"]\n",
    "# One-hot encode the integer labels\n",
    "y_test = to_categorical(y_test_df)\n",
    "y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52025, 6)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output layer has 13 columns that are one-hot encoded\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "model.add(Dense(y_train.shape[1], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52025/52025 - 4s - loss: 1713982.5837 - acc: 0.3252\n",
      "Epoch 2/100\n",
      "52025/52025 - 3s - loss: 70179.7888 - acc: 0.3277\n",
      "Epoch 3/100\n",
      "52025/52025 - 3s - loss: 10268.9431 - acc: 0.4048\n",
      "Epoch 4/100\n",
      "52025/52025 - 3s - loss: 1.4208 - acc: 0.5276\n",
      "Epoch 5/100\n",
      "52025/52025 - 3s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 6/100\n",
      "52025/52025 - 4s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 7/100\n",
      "52025/52025 - 4s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 8/100\n",
      "52025/52025 - 3s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 9/100\n",
      "52025/52025 - 3s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 10/100\n",
      "52025/52025 - 5s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 11/100\n",
      "52025/52025 - 3s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 12/100\n",
      "52025/52025 - 3s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 13/100\n",
      "52025/52025 - 3s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 14/100\n",
      "52025/52025 - 3s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 15/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 16/100\n",
      "52025/52025 - 5s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 17/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 18/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 19/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 20/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 21/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 22/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 23/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 24/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 25/100\n",
      "52025/52025 - 3s - loss: 1.4183 - acc: 0.5276\n",
      "Epoch 26/100\n",
      "52025/52025 - 3s - loss: 1.4185 - acc: 0.5276\n",
      "Epoch 27/100\n",
      "52025/52025 - 3s - loss: 1.4184 - acc: 0.5276\n",
      "Epoch 28/100\n",
      "52025/52025 - 3s - loss: 1.4184 - acc: 0.5276\n",
      "Epoch 29/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 30/100\n",
      "52025/52025 - 3s - loss: 1.4183 - acc: 0.5276\n",
      "Epoch 31/100\n",
      "52025/52025 - 3s - loss: 1.4183 - acc: 0.5276\n",
      "Epoch 32/100\n",
      "52025/52025 - 3s - loss: 1.4184 - acc: 0.5276\n",
      "Epoch 33/100\n",
      "52025/52025 - 3s - loss: 1.4184 - acc: 0.5276\n",
      "Epoch 34/100\n",
      "52025/52025 - 4s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 35/100\n",
      "52025/52025 - 3s - loss: 1.4184 - acc: 0.5276\n",
      "Epoch 36/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 37/100\n",
      "52025/52025 - 3s - loss: 1.4183 - acc: 0.5276\n",
      "Epoch 38/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 39/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 40/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 41/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 42/100\n",
      "52025/52025 - 3s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 43/100\n",
      "52025/52025 - 5s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 44/100\n",
      "52025/52025 - 4s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 45/100\n",
      "52025/52025 - 5s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 46/100\n",
      "52025/52025 - 4s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 47/100\n",
      "52025/52025 - 4s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 48/100\n",
      "52025/52025 - 4s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 49/100\n",
      "52025/52025 - 5s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 50/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 51/100\n",
      "52025/52025 - 4s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 52/100\n",
      "52025/52025 - 7s - loss: 1.4182 - acc: 0.5276\n",
      "Epoch 53/100\n",
      "52025/52025 - 7s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 54/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 55/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 56/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 57/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 58/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 59/100\n",
      "52025/52025 - 3s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 60/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 61/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 62/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 63/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 64/100\n",
      "52025/52025 - 5s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 65/100\n",
      "52025/52025 - 4s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 66/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 67/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 68/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 69/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 70/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 71/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 72/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 73/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 74/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 75/100\n",
      "52025/52025 - 4s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 76/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 77/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 78/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 79/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 80/100\n",
      "52025/52025 - 8s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 81/100\n",
      "52025/52025 - 5s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 82/100\n",
      "52025/52025 - 5s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 83/100\n",
      "52025/52025 - 4s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 84/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 85/100\n",
      "52025/52025 - 5s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 86/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 87/100\n",
      "52025/52025 - 3s - loss: 1.4181 - acc: 0.5276\n",
      "Epoch 88/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 89/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 90/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 91/100\n",
      "52025/52025 - 4s - loss: 1.4178 - acc: 0.5276\n",
      "Epoch 92/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 93/100\n",
      "52025/52025 - 3s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 94/100\n",
      "52025/52025 - 3s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 95/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 96/100\n",
      "52025/52025 - 4s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 97/100\n",
      "52025/52025 - 4s - loss: 1.4180 - acc: 0.5276\n",
      "Epoch 98/100\n",
      "52025/52025 - 9s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 99/100\n",
      "52025/52025 - 6s - loss: 1.4179 - acc: 0.5276\n",
      "Epoch 100/100\n",
      "52025/52025 - 5s - loss: 1.4180 - acc: 0.5276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23c5acf3e10>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5044/5044 - 0s - loss: 2.1604 - acc: 0.1223\n",
      "Loss: 2.1604483840391806, Accuracy: 0.12232355028390884\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_test[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>ts</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Profile_code</th>\n",
       "      <th>Activity_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47546</th>\n",
       "      <td>-0.433777</td>\n",
       "      <td>-0.842545</td>\n",
       "      <td>-0.322769</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47547</th>\n",
       "      <td>-0.443207</td>\n",
       "      <td>-0.849686</td>\n",
       "      <td>-0.307556</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47548</th>\n",
       "      <td>-0.433167</td>\n",
       "      <td>-0.844559</td>\n",
       "      <td>-0.314667</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47549</th>\n",
       "      <td>-0.397507</td>\n",
       "      <td>-0.851089</td>\n",
       "      <td>-0.307800</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47550</th>\n",
       "      <td>-0.373840</td>\n",
       "      <td>-0.853729</td>\n",
       "      <td>-0.264847</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47551</th>\n",
       "      <td>-0.398605</td>\n",
       "      <td>-0.855621</td>\n",
       "      <td>-0.305389</td>\n",
       "      <td>1578594935</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47552</th>\n",
       "      <td>-0.534897</td>\n",
       "      <td>-0.817230</td>\n",
       "      <td>-0.170517</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47553</th>\n",
       "      <td>-0.644028</td>\n",
       "      <td>-0.735794</td>\n",
       "      <td>-0.284256</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47554</th>\n",
       "      <td>-0.681870</td>\n",
       "      <td>-0.655197</td>\n",
       "      <td>-0.369614</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>-0.556976</td>\n",
       "      <td>-0.812241</td>\n",
       "      <td>-0.322922</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>-0.492615</td>\n",
       "      <td>-0.790024</td>\n",
       "      <td>-0.288437</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>-0.507904</td>\n",
       "      <td>-0.820496</td>\n",
       "      <td>-0.292831</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>-0.489441</td>\n",
       "      <td>-0.849335</td>\n",
       "      <td>-0.365692</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>-0.391479</td>\n",
       "      <td>-0.803070</td>\n",
       "      <td>-0.306610</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47560</th>\n",
       "      <td>-0.455536</td>\n",
       "      <td>-0.802643</td>\n",
       "      <td>-0.303726</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47561</th>\n",
       "      <td>-0.513184</td>\n",
       "      <td>-0.802979</td>\n",
       "      <td>-0.285706</td>\n",
       "      <td>1578594936</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47562</th>\n",
       "      <td>-0.487991</td>\n",
       "      <td>-0.813446</td>\n",
       "      <td>-0.272919</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47563</th>\n",
       "      <td>-0.516861</td>\n",
       "      <td>-0.808792</td>\n",
       "      <td>-0.279816</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47564</th>\n",
       "      <td>-0.513351</td>\n",
       "      <td>-0.801285</td>\n",
       "      <td>-0.262329</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47565</th>\n",
       "      <td>-0.679657</td>\n",
       "      <td>-0.743546</td>\n",
       "      <td>-0.203033</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47566</th>\n",
       "      <td>-0.530182</td>\n",
       "      <td>-0.840652</td>\n",
       "      <td>-0.255463</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47567</th>\n",
       "      <td>-0.561264</td>\n",
       "      <td>-0.803452</td>\n",
       "      <td>-0.218216</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47568</th>\n",
       "      <td>-0.575607</td>\n",
       "      <td>-0.770615</td>\n",
       "      <td>-0.228210</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47569</th>\n",
       "      <td>-0.562042</td>\n",
       "      <td>-0.781021</td>\n",
       "      <td>-0.218704</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47570</th>\n",
       "      <td>-0.553253</td>\n",
       "      <td>-0.822235</td>\n",
       "      <td>-0.200455</td>\n",
       "      <td>1578594937</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47571</th>\n",
       "      <td>-0.576523</td>\n",
       "      <td>-0.759109</td>\n",
       "      <td>-0.182831</td>\n",
       "      <td>1578594938</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47572</th>\n",
       "      <td>-0.596634</td>\n",
       "      <td>-0.807938</td>\n",
       "      <td>-0.210556</td>\n",
       "      <td>1578594938</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47573</th>\n",
       "      <td>-0.587326</td>\n",
       "      <td>-0.798599</td>\n",
       "      <td>-0.193558</td>\n",
       "      <td>1578594938</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47574</th>\n",
       "      <td>-0.598328</td>\n",
       "      <td>-0.778793</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>1578594938</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47575</th>\n",
       "      <td>-0.615875</td>\n",
       "      <td>-0.758865</td>\n",
       "      <td>-0.211273</td>\n",
       "      <td>1578594938</td>\n",
       "      <td>stand</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52560</th>\n",
       "      <td>-0.304504</td>\n",
       "      <td>-0.430618</td>\n",
       "      <td>-0.477585</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52561</th>\n",
       "      <td>-0.308487</td>\n",
       "      <td>-0.468613</td>\n",
       "      <td>-0.439636</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52562</th>\n",
       "      <td>-0.463867</td>\n",
       "      <td>-0.366653</td>\n",
       "      <td>-0.436508</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52563</th>\n",
       "      <td>-0.490295</td>\n",
       "      <td>-0.396790</td>\n",
       "      <td>-0.527954</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52564</th>\n",
       "      <td>-0.874435</td>\n",
       "      <td>-0.815506</td>\n",
       "      <td>-0.385330</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52565</th>\n",
       "      <td>-1.210861</td>\n",
       "      <td>-0.980652</td>\n",
       "      <td>-0.655090</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52566</th>\n",
       "      <td>-0.854599</td>\n",
       "      <td>-0.568939</td>\n",
       "      <td>-0.371887</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52567</th>\n",
       "      <td>-0.612808</td>\n",
       "      <td>-0.354004</td>\n",
       "      <td>-0.293518</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52568</th>\n",
       "      <td>-0.603500</td>\n",
       "      <td>-0.417587</td>\n",
       "      <td>-0.334503</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52569</th>\n",
       "      <td>-0.531601</td>\n",
       "      <td>-0.306000</td>\n",
       "      <td>-0.553925</td>\n",
       "      <td>1578596222</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52570</th>\n",
       "      <td>-0.654587</td>\n",
       "      <td>-0.433090</td>\n",
       "      <td>-0.408249</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52571</th>\n",
       "      <td>-1.213959</td>\n",
       "      <td>-1.153809</td>\n",
       "      <td>-0.614014</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52572</th>\n",
       "      <td>-0.850616</td>\n",
       "      <td>-0.828644</td>\n",
       "      <td>-0.642487</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52573</th>\n",
       "      <td>-0.512299</td>\n",
       "      <td>-0.343735</td>\n",
       "      <td>-0.413757</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52574</th>\n",
       "      <td>-0.339340</td>\n",
       "      <td>-0.372101</td>\n",
       "      <td>-0.254990</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52575</th>\n",
       "      <td>-0.339798</td>\n",
       "      <td>-0.260971</td>\n",
       "      <td>-0.512619</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52576</th>\n",
       "      <td>-0.605942</td>\n",
       "      <td>-0.430695</td>\n",
       "      <td>-0.706360</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52577</th>\n",
       "      <td>-1.531631</td>\n",
       "      <td>-1.154373</td>\n",
       "      <td>-0.381546</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>-1.185959</td>\n",
       "      <td>-0.573029</td>\n",
       "      <td>-0.278320</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>-0.609406</td>\n",
       "      <td>-0.595001</td>\n",
       "      <td>-0.287872</td>\n",
       "      <td>1578596223</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>-0.654373</td>\n",
       "      <td>-0.364227</td>\n",
       "      <td>-0.203339</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>-0.809372</td>\n",
       "      <td>-0.310638</td>\n",
       "      <td>-0.278030</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>-0.965286</td>\n",
       "      <td>-0.714569</td>\n",
       "      <td>-0.325806</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52583</th>\n",
       "      <td>-0.855957</td>\n",
       "      <td>-0.659119</td>\n",
       "      <td>-0.321442</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52584</th>\n",
       "      <td>-0.592422</td>\n",
       "      <td>-0.576523</td>\n",
       "      <td>-0.301346</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52585</th>\n",
       "      <td>-0.664154</td>\n",
       "      <td>-0.567200</td>\n",
       "      <td>-0.291702</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52586</th>\n",
       "      <td>-0.719528</td>\n",
       "      <td>-0.607727</td>\n",
       "      <td>-0.309525</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52587</th>\n",
       "      <td>-0.683014</td>\n",
       "      <td>-0.617081</td>\n",
       "      <td>-0.304840</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52588</th>\n",
       "      <td>-0.726517</td>\n",
       "      <td>-0.634933</td>\n",
       "      <td>-0.326462</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52589</th>\n",
       "      <td>-0.694916</td>\n",
       "      <td>-0.605682</td>\n",
       "      <td>-0.321381</td>\n",
       "      <td>1578596224</td>\n",
       "      <td>stairsd</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5044 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         Y         Z          ts Activity  Profile_code  \\\n",
       "47546 -0.433777 -0.842545 -0.322769  1578594935    stand             4   \n",
       "47547 -0.443207 -0.849686 -0.307556  1578594935    stand             4   \n",
       "47548 -0.433167 -0.844559 -0.314667  1578594935    stand             4   \n",
       "47549 -0.397507 -0.851089 -0.307800  1578594935    stand             4   \n",
       "47550 -0.373840 -0.853729 -0.264847  1578594935    stand             4   \n",
       "47551 -0.398605 -0.855621 -0.305389  1578594935    stand             4   \n",
       "47552 -0.534897 -0.817230 -0.170517  1578594936    stand             4   \n",
       "47553 -0.644028 -0.735794 -0.284256  1578594936    stand             4   \n",
       "47554 -0.681870 -0.655197 -0.369614  1578594936    stand             4   \n",
       "47555 -0.556976 -0.812241 -0.322922  1578594936    stand             4   \n",
       "47556 -0.492615 -0.790024 -0.288437  1578594936    stand             4   \n",
       "47557 -0.507904 -0.820496 -0.292831  1578594936    stand             4   \n",
       "47558 -0.489441 -0.849335 -0.365692  1578594936    stand             4   \n",
       "47559 -0.391479 -0.803070 -0.306610  1578594936    stand             4   \n",
       "47560 -0.455536 -0.802643 -0.303726  1578594936    stand             4   \n",
       "47561 -0.513184 -0.802979 -0.285706  1578594936    stand             4   \n",
       "47562 -0.487991 -0.813446 -0.272919  1578594937    stand             4   \n",
       "47563 -0.516861 -0.808792 -0.279816  1578594937    stand             4   \n",
       "47564 -0.513351 -0.801285 -0.262329  1578594937    stand             4   \n",
       "47565 -0.679657 -0.743546 -0.203033  1578594937    stand             4   \n",
       "47566 -0.530182 -0.840652 -0.255463  1578594937    stand             4   \n",
       "47567 -0.561264 -0.803452 -0.218216  1578594937    stand             4   \n",
       "47568 -0.575607 -0.770615 -0.228210  1578594937    stand             4   \n",
       "47569 -0.562042 -0.781021 -0.218704  1578594937    stand             4   \n",
       "47570 -0.553253 -0.822235 -0.200455  1578594937    stand             4   \n",
       "47571 -0.576523 -0.759109 -0.182831  1578594938    stand             4   \n",
       "47572 -0.596634 -0.807938 -0.210556  1578594938    stand             4   \n",
       "47573 -0.587326 -0.798599 -0.193558  1578594938    stand             4   \n",
       "47574 -0.598328 -0.778793 -0.207153  1578594938    stand             4   \n",
       "47575 -0.615875 -0.758865 -0.211273  1578594938    stand             4   \n",
       "...         ...       ...       ...         ...      ...           ...   \n",
       "52560 -0.304504 -0.430618 -0.477585  1578596222  stairsd             4   \n",
       "52561 -0.308487 -0.468613 -0.439636  1578596222  stairsd             4   \n",
       "52562 -0.463867 -0.366653 -0.436508  1578596222  stairsd             4   \n",
       "52563 -0.490295 -0.396790 -0.527954  1578596222  stairsd             4   \n",
       "52564 -0.874435 -0.815506 -0.385330  1578596222  stairsd             4   \n",
       "52565 -1.210861 -0.980652 -0.655090  1578596222  stairsd             4   \n",
       "52566 -0.854599 -0.568939 -0.371887  1578596222  stairsd             4   \n",
       "52567 -0.612808 -0.354004 -0.293518  1578596222  stairsd             4   \n",
       "52568 -0.603500 -0.417587 -0.334503  1578596222  stairsd             4   \n",
       "52569 -0.531601 -0.306000 -0.553925  1578596222  stairsd             4   \n",
       "52570 -0.654587 -0.433090 -0.408249  1578596223  stairsd             4   \n",
       "52571 -1.213959 -1.153809 -0.614014  1578596223  stairsd             4   \n",
       "52572 -0.850616 -0.828644 -0.642487  1578596223  stairsd             4   \n",
       "52573 -0.512299 -0.343735 -0.413757  1578596223  stairsd             4   \n",
       "52574 -0.339340 -0.372101 -0.254990  1578596223  stairsd             4   \n",
       "52575 -0.339798 -0.260971 -0.512619  1578596223  stairsd             4   \n",
       "52576 -0.605942 -0.430695 -0.706360  1578596223  stairsd             4   \n",
       "52577 -1.531631 -1.154373 -0.381546  1578596223  stairsd             4   \n",
       "52578 -1.185959 -0.573029 -0.278320  1578596223  stairsd             4   \n",
       "52579 -0.609406 -0.595001 -0.287872  1578596223  stairsd             4   \n",
       "52580 -0.654373 -0.364227 -0.203339  1578596224  stairsd             4   \n",
       "52581 -0.809372 -0.310638 -0.278030  1578596224  stairsd             4   \n",
       "52582 -0.965286 -0.714569 -0.325806  1578596224  stairsd             4   \n",
       "52583 -0.855957 -0.659119 -0.321442  1578596224  stairsd             4   \n",
       "52584 -0.592422 -0.576523 -0.301346  1578596224  stairsd             4   \n",
       "52585 -0.664154 -0.567200 -0.291702  1578596224  stairsd             4   \n",
       "52586 -0.719528 -0.607727 -0.309525  1578596224  stairsd             4   \n",
       "52587 -0.683014 -0.617081 -0.304840  1578596224  stairsd             4   \n",
       "52588 -0.726517 -0.634933 -0.326462  1578596224  stairsd             4   \n",
       "52589 -0.694916 -0.605682 -0.321381  1578596224  stairsd             4   \n",
       "\n",
       "       Activity_code  \n",
       "47546              4  \n",
       "47547              4  \n",
       "47548              4  \n",
       "47549              4  \n",
       "47550              4  \n",
       "47551              4  \n",
       "47552              4  \n",
       "47553              4  \n",
       "47554              4  \n",
       "47555              4  \n",
       "47556              4  \n",
       "47557              4  \n",
       "47558              4  \n",
       "47559              4  \n",
       "47560              4  \n",
       "47561              4  \n",
       "47562              4  \n",
       "47563              4  \n",
       "47564              4  \n",
       "47565              4  \n",
       "47566              4  \n",
       "47567              4  \n",
       "47568              4  \n",
       "47569              4  \n",
       "47570              4  \n",
       "47571              4  \n",
       "47572              4  \n",
       "47573              4  \n",
       "47574              4  \n",
       "47575              4  \n",
       "...              ...  \n",
       "52560              2  \n",
       "52561              2  \n",
       "52562              2  \n",
       "52563              2  \n",
       "52564              2  \n",
       "52565              2  \n",
       "52566              2  \n",
       "52567              2  \n",
       "52568              2  \n",
       "52569              2  \n",
       "52570              2  \n",
       "52571              2  \n",
       "52572              2  \n",
       "52573              2  \n",
       "52574              2  \n",
       "52575              2  \n",
       "52576              2  \n",
       "52577              2  \n",
       "52578              2  \n",
       "52579              2  \n",
       "52580              2  \n",
       "52581              2  \n",
       "52582              2  \n",
       "52583              2  \n",
       "52584              2  \n",
       "52585              2  \n",
       "52586              2  \n",
       "52587              2  \n",
       "52588              2  \n",
       "52589              2  \n",
       "\n",
       "[5044 rows x 7 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [3]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction. The result should be 5 - STANDING\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 11,306\n",
      "Trainable params: 11,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 2/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 3/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 4/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 5/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 6/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 7/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 8/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 9/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 10/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 11/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 12/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 13/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 14/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 15/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 16/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 17/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 18/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 19/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 20/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 21/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 22/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 23/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 24/100\n",
      "52025/52025 - 4s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 25/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 26/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 27/100\n",
      "52025/52025 - 5s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 28/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 29/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 30/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 31/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 32/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 33/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 34/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 35/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 36/100\n",
      "52025/52025 - 4s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 37/100\n",
      "52025/52025 - 4s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 38/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 39/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 40/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 41/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 42/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 43/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 44/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 45/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 46/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 47/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 48/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 49/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 50/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 51/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 52/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 53/100\n",
      "52025/52025 - 4s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 54/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 55/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 56/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 57/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 58/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 59/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 60/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 61/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 62/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 63/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 64/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 65/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 66/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 67/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 68/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 69/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 70/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 71/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 72/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 73/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 74/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 75/100\n",
      "52025/52025 - 4s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 76/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 77/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 78/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 79/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 80/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 81/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 82/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 83/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 84/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 85/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 86/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 87/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 88/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 89/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 90/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 91/100\n",
      "52025/52025 - 3s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 92/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 93/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 94/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 95/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 96/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 97/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 98/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 99/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n",
      "Epoch 100/100\n",
      "52025/52025 - 2s - loss: 1.4177 - acc: 0.5276\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-0e7cb024a416>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Accuracy of training data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Accuracy of validation data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Loss of training data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Loss of validation data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['acc'], 'r', label='Accuracy of training data')\n",
    "plt.plot(history.history['val_acc'], 'b', label='Accuracy of validation data')\n",
    "plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.ylabel('Accuracy and Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
